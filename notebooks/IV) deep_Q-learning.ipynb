{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import gym\n",
    "from time import time,sleep\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from rl_introduction.tools import Agent, DeepAgent, plot_values_lake, policy_improvement, discount_cumsum, run_experiment_episode_train\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the state spaces is continous. It is necessary to have a function for the Q value. A common way to represent and update this function, it is to use parametric function (as neural network).\n",
    "In other words, we are looking for $\\theta \\in \\mathbb{R}^d$ such as \n",
    "$\\forall s Q_\\theta(s,a) = \\mathbb{E}_\\pi[G_t | S_t = s, A_t = a]$. We follow the same idea as q-learning:\n",
    "we eant to update $Q_\\theta(S_t,A_t)$ using the target $R_{t+1}+\\gamma \\max_a Q(S_{t+1},a)$. A natural loss is the mean square error:\n",
    "\n",
    "$L(\\theta) = \\mathbb{E}_{s,a\\sim Q} [(y_t - Q(s,a,\\theta))^2]$\n",
    "\n",
    "\n",
    "\n",
    "$y = R_{t+1} + \\gamma \\max_a Q(S_{t+1},a,\\theta)$\n",
    "\n",
    "We have 2 ways to write our function:\n",
    "1. $Q_\\theta : S\\times A \\rightarrow \\mathbb{R}$\n",
    "\n",
    "in this case greedy policy looks like $\\pi(.|s) = \\arg\\max([Q_\\theta(s,a_0), Q_\\theta(s,a_1),... Q_\\theta(s,a_{dim(A)}]) $\n",
    "\n",
    "The target is $y = R_{t+1} + \\gamma \\max_a Q(S_{t+1},a,\\theta)$\n",
    "2. $Q_\\theta : S \\rightarrow \\mathbb{R}^{dim(A)}$\n",
    "\n",
    "in this case greedy policy looks like $\\pi(.|s) = \\arg\\max(Q_\\theta(s))$\n",
    "\n",
    "The target is $y_i = R_{t+1} + \\gamma \\max_a Q(S_{t+1},a,\\theta)$ for i corresponding to the played action, $Q_\\theta(s_t)_i$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(state_sim, action_dim):\n",
    "    input_state = Input(name='input_state', shape=(state_dim,), dtype='float32')\n",
    "    x = Dense(32, activation='relu')(input_state)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(action_dim, activation='linear')(x)\n",
    "    model = Model(inputs=input_state, outputs=x)\n",
    "    model.compile(loss='mse',optimizer=Adam(learning_rate=1e-2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgent(DeepAgent):\n",
    "    def __init__(self, env, compiled_model, gamma = .99, epsilon = .1):\n",
    "        super().__init__(env, gamma, epsilon)\n",
    "        \n",
    "        self.model = compiled_model\n",
    "        self.model.summary()\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.env.action_space.n)\n",
    "        else:\n",
    "            predicted_Qs = self.model.predict(state.reshape(1, -1))[0]\n",
    "            return np.argmax(predicted_Qs) \n",
    "    \n",
    "    def train(self, current_state, action, reward, next_state, done):\n",
    "        predicted_Q_nexts = self.model.predict(next_state.reshape(1, -1))[0]\n",
    "        target = self.model.predict(current_state.reshape(1, -1))[0]\n",
    "        if done is True:\n",
    "            target[action] = reward\n",
    "        else:\n",
    "            target[action] = reward + self.gamma * np.max(predicted_Q_nexts)\n",
    "        self.model.train_on_batch(current_state.reshape(1, -1), target.reshape(1, -1))\n",
    "        #self.model.fit(current_state.reshape(1, -1), target.reshape(1, -1), batch_size=1, verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_state (InputLayer)     [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0 - cum reward 8.0\n",
      "episode: 1 - cum reward 10.0\n",
      "episode: 2 - cum reward 10.0\n",
      "episode: 3 - cum reward 10.0\n",
      "episode: 4 - cum reward 9.0\n",
      "episode: 5 - cum reward 11.0\n",
      "episode: 6 - cum reward 9.0\n",
      "episode: 7 - cum reward 10.0\n",
      "episode: 8 - cum reward 10.0\n",
      "episode: 9 - cum reward 10.0\n",
      "episode: 10 - cum reward 12.0\n",
      "episode: 11 - cum reward 9.0\n",
      "episode: 12 - cum reward 10.0\n",
      "episode: 13 - cum reward 9.0\n",
      "episode: 14 - cum reward 10.0\n",
      "episode: 15 - cum reward 13.0\n",
      "episode: 16 - cum reward 10.0\n",
      "episode: 17 - cum reward 10.0\n",
      "episode: 18 - cum reward 10.0\n",
      "episode: 19 - cum reward 10.0\n",
      "episode: 20 - cum reward 11.0\n",
      "episode: 21 - cum reward 10.0\n",
      "episode: 22 - cum reward 9.0\n",
      "episode: 23 - cum reward 9.0\n",
      "episode: 24 - cum reward 9.0\n",
      "episode: 25 - cum reward 11.0\n",
      "episode: 26 - cum reward 10.0\n",
      "episode: 27 - cum reward 10.0\n",
      "episode: 28 - cum reward 10.0\n",
      "episode: 29 - cum reward 10.0\n",
      "episode: 30 - cum reward 10.0\n",
      "episode: 31 - cum reward 11.0\n",
      "episode: 32 - cum reward 9.0\n",
      "episode: 33 - cum reward 10.0\n",
      "episode: 34 - cum reward 11.0\n",
      "episode: 35 - cum reward 9.0\n",
      "episode: 36 - cum reward 10.0\n",
      "episode: 37 - cum reward 10.0\n",
      "episode: 38 - cum reward 9.0\n",
      "episode: 39 - cum reward 9.0\n",
      "episode: 40 - cum reward 9.0\n",
      "episode: 41 - cum reward 10.0\n",
      "episode: 42 - cum reward 9.0\n",
      "episode: 43 - cum reward 9.0\n",
      "episode: 44 - cum reward 10.0\n",
      "episode: 45 - cum reward 11.0\n",
      "episode: 46 - cum reward 9.0\n",
      "episode: 47 - cum reward 13.0\n",
      "episode: 48 - cum reward 11.0\n",
      "episode: 49 - cum reward 11.0\n",
      "episode: 50 - cum reward 9.0\n",
      "episode: 51 - cum reward 10.0\n",
      "episode: 52 - cum reward 12.0\n",
      "episode: 53 - cum reward 10.0\n",
      "episode: 54 - cum reward 9.0\n",
      "episode: 55 - cum reward 11.0\n",
      "episode: 56 - cum reward 8.0\n",
      "episode: 57 - cum reward 9.0\n",
      "episode: 58 - cum reward 10.0\n",
      "episode: 59 - cum reward 9.0\n",
      "episode: 60 - cum reward 8.0\n",
      "episode: 61 - cum reward 10.0\n",
      "episode: 62 - cum reward 10.0\n",
      "episode: 63 - cum reward 12.0\n",
      "episode: 64 - cum reward 11.0\n",
      "episode: 65 - cum reward 10.0\n",
      "episode: 66 - cum reward 9.0\n",
      "episode: 67 - cum reward 12.0\n",
      "episode: 68 - cum reward 10.0\n",
      "episode: 69 - cum reward 11.0\n",
      "episode: 70 - cum reward 10.0\n",
      "episode: 71 - cum reward 8.0\n",
      "episode: 72 - cum reward 13.0\n",
      "episode: 73 - cum reward 10.0\n",
      "episode: 74 - cum reward 12.0\n",
      "episode: 75 - cum reward 12.0\n",
      "episode: 76 - cum reward 10.0\n",
      "episode: 77 - cum reward 14.0\n",
      "episode: 78 - cum reward 10.0\n",
      "episode: 79 - cum reward 16.0\n",
      "episode: 80 - cum reward 16.0\n",
      "episode: 81 - cum reward 13.0\n",
      "episode: 82 - cum reward 13.0\n",
      "episode: 83 - cum reward 18.0\n",
      "episode: 84 - cum reward 16.0\n",
      "episode: 85 - cum reward 30.0\n",
      "episode: 86 - cum reward 45.0\n",
      "episode: 87 - cum reward 11.0\n",
      "episode: 88 - cum reward 12.0\n",
      "episode: 89 - cum reward 10.0\n",
      "episode: 90 - cum reward 36.0\n",
      "episode: 91 - cum reward 19.0\n",
      "episode: 92 - cum reward 10.0\n",
      "episode: 93 - cum reward 21.0\n",
      "episode: 94 - cum reward 12.0\n",
      "episode: 95 - cum reward 9.0\n",
      "episode: 96 - cum reward 10.0\n",
      "episode: 97 - cum reward 12.0\n",
      "episode: 98 - cum reward 11.0\n",
      "episode: 99 - cum reward 12.0\n",
      "episode: 100 - cum reward 11.0\n",
      "episode: 101 - cum reward 9.0\n",
      "episode: 102 - cum reward 11.0\n",
      "episode: 103 - cum reward 11.0\n",
      "episode: 104 - cum reward 10.0\n",
      "episode: 105 - cum reward 11.0\n",
      "episode: 106 - cum reward 14.0\n",
      "episode: 107 - cum reward 13.0\n",
      "episode: 108 - cum reward 14.0\n",
      "episode: 109 - cum reward 11.0\n",
      "episode: 110 - cum reward 9.0\n",
      "episode: 111 - cum reward 10.0\n",
      "episode: 112 - cum reward 10.0\n",
      "episode: 113 - cum reward 8.0\n",
      "episode: 114 - cum reward 10.0\n",
      "episode: 115 - cum reward 11.0\n",
      "episode: 116 - cum reward 11.0\n",
      "episode: 117 - cum reward 15.0\n",
      "episode: 118 - cum reward 15.0\n",
      "episode: 119 - cum reward 13.0\n",
      "episode: 120 - cum reward 9.0\n",
      "episode: 121 - cum reward 9.0\n",
      "episode: 122 - cum reward 11.0\n",
      "episode: 123 - cum reward 10.0\n",
      "episode: 124 - cum reward 8.0\n",
      "episode: 125 - cum reward 9.0\n",
      "episode: 126 - cum reward 10.0\n",
      "episode: 127 - cum reward 9.0\n",
      "episode: 128 - cum reward 15.0\n",
      "episode: 129 - cum reward 9.0\n",
      "episode: 130 - cum reward 11.0\n",
      "episode: 131 - cum reward 9.0\n",
      "episode: 132 - cum reward 10.0\n",
      "episode: 133 - cum reward 11.0\n",
      "episode: 134 - cum reward 10.0\n",
      "episode: 135 - cum reward 10.0\n",
      "episode: 136 - cum reward 9.0\n",
      "episode: 137 - cum reward 13.0\n",
      "episode: 138 - cum reward 15.0\n",
      "episode: 139 - cum reward 13.0\n",
      "episode: 140 - cum reward 15.0\n",
      "episode: 141 - cum reward 17.0\n",
      "episode: 142 - cum reward 17.0\n",
      "episode: 143 - cum reward 70.0\n",
      "episode: 144 - cum reward 11.0\n",
      "episode: 145 - cum reward 11.0\n",
      "episode: 146 - cum reward 9.0\n",
      "episode: 147 - cum reward 10.0\n",
      "episode: 148 - cum reward 10.0\n",
      "episode: 149 - cum reward 12.0\n",
      "episode: 150 - cum reward 10.0\n",
      "episode: 151 - cum reward 10.0\n",
      "episode: 152 - cum reward 11.0\n",
      "episode: 153 - cum reward 11.0\n",
      "episode: 154 - cum reward 10.0\n",
      "episode: 155 - cum reward 12.0\n",
      "episode: 156 - cum reward 13.0\n",
      "episode: 157 - cum reward 10.0\n",
      "episode: 158 - cum reward 10.0\n",
      "episode: 159 - cum reward 10.0\n",
      "episode: 160 - cum reward 8.0\n",
      "episode: 161 - cum reward 14.0\n",
      "episode: 162 - cum reward 9.0\n",
      "episode: 163 - cum reward 10.0\n",
      "episode: 164 - cum reward 10.0\n",
      "episode: 165 - cum reward 12.0\n",
      "episode: 166 - cum reward 11.0\n",
      "episode: 167 - cum reward 10.0\n",
      "episode: 168 - cum reward 11.0\n",
      "episode: 169 - cum reward 9.0\n",
      "episode: 170 - cum reward 10.0\n",
      "episode: 171 - cum reward 11.0\n",
      "episode: 172 - cum reward 15.0\n",
      "episode: 173 - cum reward 13.0\n",
      "episode: 174 - cum reward 14.0\n",
      "episode: 175 - cum reward 10.0\n",
      "episode: 176 - cum reward 12.0\n",
      "episode: 177 - cum reward 11.0\n",
      "episode: 178 - cum reward 15.0\n",
      "episode: 179 - cum reward 15.0\n",
      "episode: 180 - cum reward 13.0\n",
      "episode: 181 - cum reward 12.0\n",
      "episode: 182 - cum reward 18.0\n",
      "episode: 183 - cum reward 16.0\n",
      "episode: 184 - cum reward 23.0\n",
      "episode: 185 - cum reward 20.0\n",
      "episode: 186 - cum reward 35.0\n",
      "episode: 187 - cum reward 61.0\n",
      "episode: 188 - cum reward 31.0\n",
      "episode: 189 - cum reward 19.0\n",
      "episode: 190 - cum reward 13.0\n",
      "episode: 191 - cum reward 20.0\n",
      "episode: 192 - cum reward 23.0\n",
      "episode: 193 - cum reward 92.0\n",
      "episode: 194 - cum reward 41.0\n",
      "episode: 195 - cum reward 26.0\n",
      "episode: 196 - cum reward 70.0\n",
      "episode: 197 - cum reward 24.0\n",
      "episode: 198 - cum reward 29.0\n",
      "episode: 199 - cum reward 35.0\n",
      "episode: 200 - cum reward 21.0\n",
      "episode: 201 - cum reward 24.0\n",
      "episode: 202 - cum reward 22.0\n",
      "episode: 203 - cum reward 31.0\n",
      "episode: 204 - cum reward 54.0\n",
      "episode: 205 - cum reward 17.0\n",
      "episode: 206 - cum reward 14.0\n",
      "episode: 207 - cum reward 18.0\n",
      "episode: 208 - cum reward 38.0\n",
      "episode: 209 - cum reward 66.0\n",
      "episode: 210 - cum reward 33.0\n",
      "episode: 211 - cum reward 34.0\n",
      "episode: 212 - cum reward 47.0\n",
      "episode: 213 - cum reward 29.0\n",
      "episode: 214 - cum reward 22.0\n",
      "episode: 215 - cum reward 20.0\n",
      "episode: 216 - cum reward 15.0\n",
      "episode: 217 - cum reward 16.0\n",
      "episode: 218 - cum reward 14.0\n",
      "episode: 219 - cum reward 16.0\n",
      "episode: 220 - cum reward 13.0\n",
      "episode: 221 - cum reward 27.0\n",
      "episode: 222 - cum reward 23.0\n",
      "episode: 223 - cum reward 26.0\n",
      "episode: 224 - cum reward 40.0\n",
      "episode: 225 - cum reward 17.0\n",
      "episode: 226 - cum reward 18.0\n",
      "episode: 227 - cum reward 17.0\n",
      "episode: 228 - cum reward 21.0\n",
      "episode: 229 - cum reward 20.0\n",
      "episode: 230 - cum reward 18.0\n",
      "episode: 231 - cum reward 16.0\n",
      "episode: 232 - cum reward 40.0\n",
      "episode: 233 - cum reward 35.0\n",
      "episode: 234 - cum reward 21.0\n",
      "episode: 235 - cum reward 83.0\n",
      "episode: 236 - cum reward 31.0\n",
      "episode: 237 - cum reward 27.0\n",
      "episode: 238 - cum reward 61.0\n",
      "episode: 239 - cum reward 62.0\n",
      "episode: 240 - cum reward 28.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 241 - cum reward 18.0\n",
      "episode: 242 - cum reward 33.0\n",
      "episode: 243 - cum reward 52.0\n",
      "episode: 244 - cum reward 96.0\n",
      "episode: 245 - cum reward 29.0\n",
      "episode: 246 - cum reward 40.0\n",
      "episode: 247 - cum reward 37.0\n",
      "episode: 248 - cum reward 23.0\n",
      "episode: 249 - cum reward 20.0\n",
      "episode: 250 - cum reward 27.0\n",
      "episode: 251 - cum reward 41.0\n",
      "episode: 252 - cum reward 28.0\n",
      "episode: 253 - cum reward 36.0\n",
      "episode: 254 - cum reward 43.0\n",
      "episode: 255 - cum reward 66.0\n",
      "episode: 256 - cum reward 58.0\n",
      "episode: 257 - cum reward 18.0\n",
      "episode: 258 - cum reward 31.0\n",
      "episode: 259 - cum reward 33.0\n",
      "episode: 260 - cum reward 32.0\n",
      "episode: 261 - cum reward 23.0\n",
      "episode: 262 - cum reward 17.0\n",
      "episode: 263 - cum reward 59.0\n",
      "episode: 264 - cum reward 38.0\n",
      "episode: 265 - cum reward 44.0\n",
      "episode: 266 - cum reward 44.0\n",
      "episode: 267 - cum reward 58.0\n",
      "episode: 268 - cum reward 23.0\n",
      "episode: 269 - cum reward 55.0\n",
      "episode: 270 - cum reward 61.0\n",
      "episode: 271 - cum reward 23.0\n",
      "episode: 272 - cum reward 114.0\n",
      "episode: 273 - cum reward 21.0\n",
      "episode: 274 - cum reward 15.0\n",
      "episode: 275 - cum reward 16.0\n",
      "episode: 276 - cum reward 17.0\n",
      "episode: 277 - cum reward 13.0\n",
      "episode: 278 - cum reward 16.0\n",
      "episode: 279 - cum reward 18.0\n",
      "episode: 280 - cum reward 20.0\n",
      "episode: 281 - cum reward 26.0\n",
      "episode: 282 - cum reward 56.0\n",
      "episode: 283 - cum reward 24.0\n",
      "episode: 284 - cum reward 21.0\n",
      "episode: 285 - cum reward 11.0\n",
      "episode: 286 - cum reward 17.0\n",
      "episode: 287 - cum reward 18.0\n",
      "episode: 288 - cum reward 15.0\n",
      "episode: 289 - cum reward 13.0\n",
      "episode: 290 - cum reward 11.0\n",
      "episode: 291 - cum reward 11.0\n",
      "episode: 292 - cum reward 14.0\n",
      "episode: 293 - cum reward 13.0\n",
      "episode: 294 - cum reward 18.0\n",
      "episode: 295 - cum reward 19.0\n",
      "episode: 296 - cum reward 15.0\n",
      "episode: 297 - cum reward 12.0\n",
      "episode: 298 - cum reward 20.0\n",
      "episode: 299 - cum reward 72.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'cumulative reward per episode - rand_agent')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "model = build_model(state_dim, action_dim)\n",
    "q_agent = DeepQAgent(env, model)\n",
    "rewards = run_experiment_episode_train(env, q_agent, 300)\n",
    "plt.plot(rewards)\n",
    "plt.title('cumulative reward per episode - rand_agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_i(\\theta_i) = \\mathbb{E}_{(s, a, r, s') \\sim U(D)} \\left[ \\left(r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s, a; \\theta_i)\\right)^2 \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgent_experience_replay(DeepAgent):\n",
    "    def __init__(self, env, compiled_model, gamma = .99, epsilon = .1, memory_size = 2000, batch_size = 100):\n",
    "        super().__init__(env, gamma, epsilon)\n",
    "        \n",
    "        self.model = compiled_model\n",
    "        self.model.summary()\n",
    "        \n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        \n",
    "    #def replay(self, batch_size):\n",
    "    #    x_batch =  np.zeros((batch_size, self.state_size))\n",
    "    #    y_batch =  np.zeros((batch_size, self.action_size))\n",
    "    #    minibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "    #    for i, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
    "    #        target = self.model.predict(state.reshape(1,-1))[0]\n",
    "    #        if done:\n",
    "    #            target[action] = reward\n",
    "    #        else:\n",
    "    #            target[action] = reward + self.gamma * np.max(self.model.predict(next_state.reshape(1,-1)))\n",
    "    #        x_batch[i] = state\n",
    "    #        y_batch[i] = target\n",
    "    #    return x_batch, y_batch\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = np.array(random.sample(self.memory, min(len(self.memory), batch_size)))\n",
    "        states = np.vstack(np.array(minibatch)[:,0])\n",
    "        actions = np.array(minibatch)[:,1].astype(int)\n",
    "        rewards = np.array(minibatch)[:,2]\n",
    "        next_states = np.vstack(np.array(minibatch)[:,3])\n",
    "        dones = np.array(minibatch)[:,4]\n",
    "        targets = self.model.predict(states)\n",
    "        targets_next = self.model.predict(next_states)\n",
    "        targets[np.arange(actions.size),actions] = rewards + (1 - dones) * self.gamma * np.max(targets_next, axis=1)\n",
    "        return states, targets\n",
    "    \n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.randint(self.env.action_space.n)\n",
    "            return action\n",
    "        predicted_Qs = self.model.predict(state.reshape(1, -1))[0]\n",
    "        action = np.argmax(predicted_Qs) \n",
    "        return action\n",
    "    \n",
    "    def train(self, current_state, action, reward, next_state, done):\n",
    "        self.memory.append([current_state, action, reward, next_state, done])\n",
    "        x_batch, y_batch = self.replay(self.batch_size)\n",
    "        loss = self.model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_state (InputLayer)     [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0 - cum reward 115.0\n",
      "episode: 1 - cum reward 46.0\n",
      "episode: 2 - cum reward 11.0\n",
      "episode: 3 - cum reward 10.0\n",
      "episode: 4 - cum reward 10.0\n",
      "episode: 5 - cum reward 15.0\n",
      "episode: 6 - cum reward 11.0\n",
      "episode: 7 - cum reward 11.0\n",
      "episode: 8 - cum reward 12.0\n",
      "episode: 9 - cum reward 15.0\n",
      "episode: 10 - cum reward 28.0\n",
      "episode: 11 - cum reward 10.0\n",
      "episode: 12 - cum reward 10.0\n",
      "episode: 13 - cum reward 9.0\n",
      "episode: 14 - cum reward 10.0\n",
      "episode: 15 - cum reward 35.0\n",
      "episode: 16 - cum reward 140.0\n",
      "episode: 17 - cum reward 107.0\n",
      "episode: 18 - cum reward 112.0\n",
      "episode: 19 - cum reward 27.0\n",
      "episode: 20 - cum reward 90.0\n",
      "episode: 21 - cum reward 54.0\n",
      "episode: 22 - cum reward 40.0\n",
      "episode: 23 - cum reward 46.0\n",
      "episode: 24 - cum reward 74.0\n",
      "episode: 25 - cum reward 65.0\n",
      "episode: 26 - cum reward 67.0\n",
      "episode: 27 - cum reward 69.0\n",
      "episode: 28 - cum reward 120.0\n",
      "episode: 29 - cum reward 110.0\n",
      "episode: 30 - cum reward 98.0\n",
      "episode: 31 - cum reward 116.0\n",
      "episode: 32 - cum reward 200.0\n",
      "episode: 33 - cum reward 200.0\n",
      "episode: 34 - cum reward 200.0\n",
      "episode: 35 - cum reward 200.0\n",
      "episode: 36 - cum reward 200.0\n",
      "episode: 37 - cum reward 200.0\n",
      "episode: 38 - cum reward 200.0\n",
      "episode: 39 - cum reward 200.0\n",
      "episode: 40 - cum reward 200.0\n",
      "episode: 41 - cum reward 200.0\n",
      "episode: 42 - cum reward 200.0\n",
      "episode: 43 - cum reward 200.0\n",
      "episode: 44 - cum reward 200.0\n",
      "episode: 45 - cum reward 200.0\n",
      "episode: 46 - cum reward 200.0\n",
      "episode: 47 - cum reward 200.0\n",
      "episode: 48 - cum reward 200.0\n",
      "episode: 49 - cum reward 200.0\n",
      "episode: 50 - cum reward 200.0\n",
      "episode: 51 - cum reward 200.0\n",
      "episode: 52 - cum reward 200.0\n",
      "episode: 53 - cum reward 135.0\n",
      "episode: 54 - cum reward 124.0\n",
      "episode: 55 - cum reward 58.0\n",
      "episode: 56 - cum reward 27.0\n",
      "episode: 57 - cum reward 19.0\n",
      "episode: 58 - cum reward 12.0\n",
      "episode: 59 - cum reward 13.0\n",
      "episode: 60 - cum reward 70.0\n",
      "episode: 61 - cum reward 103.0\n",
      "episode: 62 - cum reward 55.0\n",
      "episode: 63 - cum reward 32.0\n",
      "episode: 64 - cum reward 32.0\n",
      "episode: 65 - cum reward 20.0\n",
      "episode: 66 - cum reward 21.0\n",
      "episode: 67 - cum reward 40.0\n",
      "episode: 68 - cum reward 200.0\n",
      "episode: 69 - cum reward 200.0\n",
      "episode: 70 - cum reward 200.0\n",
      "episode: 71 - cum reward 200.0\n",
      "episode: 72 - cum reward 200.0\n",
      "episode: 73 - cum reward 200.0\n",
      "episode: 74 - cum reward 200.0\n",
      "episode: 75 - cum reward 200.0\n",
      "episode: 76 - cum reward 200.0\n",
      "episode: 77 - cum reward 200.0\n",
      "episode: 78 - cum reward 200.0\n",
      "episode: 79 - cum reward 200.0\n",
      "episode: 80 - cum reward 200.0\n",
      "episode: 81 - cum reward 200.0\n",
      "episode: 82 - cum reward 200.0\n",
      "episode: 83 - cum reward 200.0\n",
      "episode: 84 - cum reward 200.0\n",
      "episode: 85 - cum reward 200.0\n",
      "episode: 86 - cum reward 200.0\n",
      "episode: 87 - cum reward 200.0\n",
      "episode: 88 - cum reward 17.0\n",
      "episode: 89 - cum reward 13.0\n",
      "episode: 90 - cum reward 200.0\n",
      "episode: 91 - cum reward 200.0\n",
      "episode: 92 - cum reward 200.0\n",
      "episode: 93 - cum reward 196.0\n",
      "episode: 94 - cum reward 200.0\n",
      "episode: 95 - cum reward 200.0\n",
      "episode: 96 - cum reward 200.0\n",
      "episode: 97 - cum reward 200.0\n",
      "episode: 98 - cum reward 200.0\n",
      "episode: 99 - cum reward 200.0\n",
      "episode: 100 - cum reward 200.0\n",
      "episode: 101 - cum reward 200.0\n",
      "episode: 102 - cum reward 200.0\n",
      "episode: 103 - cum reward 200.0\n",
      "episode: 104 - cum reward 200.0\n",
      "episode: 105 - cum reward 200.0\n",
      "episode: 106 - cum reward 200.0\n",
      "episode: 107 - cum reward 200.0\n",
      "episode: 108 - cum reward 200.0\n",
      "episode: 109 - cum reward 200.0\n",
      "episode: 110 - cum reward 200.0\n",
      "episode: 111 - cum reward 200.0\n",
      "episode: 112 - cum reward 200.0\n",
      "episode: 113 - cum reward 200.0\n",
      "episode: 114 - cum reward 200.0\n",
      "episode: 115 - cum reward 19.0\n",
      "episode: 116 - cum reward 43.0\n",
      "episode: 117 - cum reward 16.0\n",
      "episode: 118 - cum reward 200.0\n",
      "episode: 119 - cum reward 198.0\n",
      "episode: 120 - cum reward 189.0\n",
      "episode: 121 - cum reward 200.0\n",
      "episode: 122 - cum reward 200.0\n",
      "episode: 123 - cum reward 200.0\n",
      "episode: 124 - cum reward 200.0\n",
      "episode: 125 - cum reward 200.0\n",
      "episode: 126 - cum reward 200.0\n",
      "episode: 127 - cum reward 200.0\n",
      "episode: 128 - cum reward 200.0\n",
      "episode: 129 - cum reward 200.0\n",
      "episode: 130 - cum reward 200.0\n",
      "episode: 131 - cum reward 195.0\n",
      "episode: 132 - cum reward 177.0\n",
      "episode: 133 - cum reward 144.0\n",
      "episode: 134 - cum reward 103.0\n",
      "episode: 135 - cum reward 15.0\n",
      "episode: 136 - cum reward 14.0\n",
      "episode: 137 - cum reward 200.0\n",
      "episode: 138 - cum reward 200.0\n",
      "episode: 139 - cum reward 196.0\n",
      "episode: 140 - cum reward 180.0\n",
      "episode: 141 - cum reward 174.0\n",
      "episode: 142 - cum reward 196.0\n",
      "episode: 143 - cum reward 200.0\n",
      "episode: 144 - cum reward 199.0\n",
      "episode: 145 - cum reward 200.0\n",
      "episode: 146 - cum reward 200.0\n",
      "episode: 147 - cum reward 200.0\n",
      "episode: 148 - cum reward 200.0\n",
      "episode: 149 - cum reward 200.0\n",
      "episode: 150 - cum reward 200.0\n",
      "episode: 151 - cum reward 200.0\n",
      "episode: 152 - cum reward 200.0\n",
      "episode: 153 - cum reward 200.0\n",
      "episode: 154 - cum reward 200.0\n",
      "episode: 155 - cum reward 200.0\n",
      "episode: 156 - cum reward 200.0\n",
      "episode: 157 - cum reward 200.0\n",
      "episode: 158 - cum reward 200.0\n",
      "episode: 159 - cum reward 200.0\n",
      "episode: 160 - cum reward 200.0\n",
      "episode: 161 - cum reward 200.0\n",
      "episode: 162 - cum reward 200.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-13350ce21b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mq_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepQAgent_experience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment_episode_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cumulative reward per episode - rand_agent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/rl_introduction/tools.py\u001b[0m in \u001b[0;36mrun_experiment_episode_train\u001b[0;34m(env, agent, nb_episode)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-feb10d97c8c1>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpredicted_Qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_Qs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1613\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m     \"\"\"\n\u001b[0;32m-> 1615\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   3956\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 3958\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   3959\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m           optional_features=optional_features)\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    338\u001b[0m       \"\"\"\n\u001b[1;32m    339\u001b[0m       \u001b[0mnum_in_full_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_full_batches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0mfirst_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_in_full_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m       first_k_indices = array_ops.reshape(\n\u001b[1;32m    342\u001b[0m           first_k_indices, [num_full_batches, batch_size])\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   \"\"\"\n\u001b[0;32m--> 951\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   8449\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8450\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 8451\u001b[0;31m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[1;32m   8452\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8453\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    466\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m               \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m               preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    300\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    301\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 302\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3322\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3323\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36mrelease\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotifyAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mnotify_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mnotify_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \"\"\"Wake up all threads waiting on this condition.\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "model = build_model(state_dim, action_dim)\n",
    "\n",
    "q_agent = DeepQAgent_experience_replay(env, model)\n",
    "rewards = run_experiment_episode_train(env, q_agent, 100)\n",
    "plt.plot(rewards)\n",
    "plt.title('cumulative reward per episode - rand_agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other improvments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clipping\n",
    "$Q(s,a):=Q(s,a)+\\alpha(clip(r+\\gamma \\arg\\max(Q(s',a'))-Q(s,a), -1, 1))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf tf.keras.losses.Huber(delta=10000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Q learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN: A reinforcement learning algorithm that combines Q-Learning with deep neural networks to let RL work for complex, high-dimensional environments, like video games, or robotics.\n",
    "Double Q Learning: Corrects the stock DQN algorithm’s tendency to sometimes overestimate the values tied to specific actions.\n",
    "Prioritized Replay: Extends DQN’s experience replay function by learning to replay memories where the real reward significantly diverges from the expected reward, letting the agent adjust itself in response to developing incorrect assumptions.\n",
    "Dueling DQN: Splits the neural network into two — one learns to provide an estimate of the value at every timestep, and the other calculates potential advantages of each action, and the two are combined for a single action-advantage Q function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
