{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import gym\n",
    "from time import time,sleep\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ddpg/policies.py:137: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "956 timesteps\n",
      "Best mean reward: -inf - Last mean reward per episode: -380.91\n",
      "Saving new best model\n",
      "1992 timesteps\n",
      "Best mean reward: -380.91 - Last mean reward per episode: -368.58\n",
      "Saving new best model\n",
      "2943 timesteps\n",
      "Best mean reward: -368.58 - Last mean reward per episode: -396.22\n",
      "3928 timesteps\n",
      "Best mean reward: -368.58 - Last mean reward per episode: -423.42\n",
      "4976 timesteps\n",
      "Best mean reward: -368.58 - Last mean reward per episode: -396.41\n",
      "5777 timesteps\n",
      "Best mean reward: -368.58 - Last mean reward per episode: -379.89\n",
      "6875 timesteps\n",
      "Best mean reward: -368.58 - Last mean reward per episode: -364.64\n",
      "Saving new best model\n",
      "7983 timesteps\n",
      "Best mean reward: -364.64 - Last mean reward per episode: -352.95\n",
      "Saving new best model\n",
      "8894 timesteps\n",
      "Best mean reward: -352.95 - Last mean reward per episode: -335.73\n",
      "Saving new best model\n",
      "9866 timesteps\n",
      "Best mean reward: -335.73 - Last mean reward per episode: -326.29\n",
      "Saving new best model\n",
      "10978 timesteps\n",
      "Best mean reward: -326.29 - Last mean reward per episode: -310.01\n",
      "Saving new best model\n",
      "11762 timesteps\n",
      "Best mean reward: -310.01 - Last mean reward per episode: -301.60\n",
      "Saving new best model\n",
      "12886 timesteps\n",
      "Best mean reward: -301.60 - Last mean reward per episode: -292.92\n",
      "Saving new best model\n",
      "13903 timesteps\n",
      "Best mean reward: -292.92 - Last mean reward per episode: -282.97\n",
      "Saving new best model\n",
      "14968 timesteps\n",
      "Best mean reward: -282.97 - Last mean reward per episode: -278.55\n",
      "Saving new best model\n",
      "15812 timesteps\n",
      "Best mean reward: -278.55 - Last mean reward per episode: -277.57\n",
      "Saving new best model\n",
      "16840 timesteps\n",
      "Best mean reward: -277.57 - Last mean reward per episode: -273.64\n",
      "Saving new best model\n",
      "17996 timesteps\n",
      "Best mean reward: -273.64 - Last mean reward per episode: -266.99\n",
      "Saving new best model\n",
      "18958 timesteps\n",
      "Best mean reward: -266.99 - Last mean reward per episode: -260.59\n",
      "Saving new best model\n",
      "19987 timesteps\n",
      "Best mean reward: -260.59 - Last mean reward per episode: -246.65\n",
      "Saving new best model\n",
      "20979 timesteps\n",
      "Best mean reward: -246.65 - Last mean reward per episode: -237.23\n",
      "Saving new best model\n",
      "21629 timesteps\n",
      "Best mean reward: -237.23 - Last mean reward per episode: -228.75\n",
      "Saving new best model\n",
      "22991 timesteps\n",
      "Best mean reward: -228.75 - Last mean reward per episode: -217.29\n",
      "Saving new best model\n",
      "23888 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -219.62\n",
      "24927 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -219.46\n",
      "25760 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -218.54\n",
      "26952 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -218.33\n",
      "27849 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -220.34\n",
      "28868 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -222.57\n",
      "29898 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -224.04\n",
      "30802 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -226.46\n",
      "31898 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -230.50\n",
      "32692 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -232.62\n",
      "33876 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -233.80\n",
      "34919 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -238.35\n",
      "35787 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -241.61\n",
      "36983 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -251.17\n",
      "37865 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -248.13\n",
      "38900 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -240.79\n",
      "39892 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -237.64\n",
      "40976 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -234.92\n",
      "41920 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -231.93\n",
      "42841 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -240.49\n",
      "43898 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -242.58\n",
      "44905 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -237.98\n",
      "45868 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -236.26\n",
      "46829 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -234.89\n",
      "47777 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -232.71\n",
      "48692 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -231.15\n",
      "49736 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -230.22\n",
      "50805 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -229.25\n",
      "51999 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -225.21\n",
      "52903 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -222.50\n",
      "53752 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -218.88\n",
      "54988 timesteps\n",
      "Best mean reward: -217.29 - Last mean reward per episode: -216.90\n",
      "Saving new best model\n",
      "55976 timesteps\n",
      "Best mean reward: -216.90 - Last mean reward per episode: -218.04\n",
      "56847 timesteps\n",
      "Best mean reward: -216.90 - Last mean reward per episode: -213.76\n",
      "Saving new best model\n",
      "57908 timesteps\n",
      "Best mean reward: -213.76 - Last mean reward per episode: -209.70\n",
      "Saving new best model\n",
      "58832 timesteps\n",
      "Best mean reward: -209.70 - Last mean reward per episode: -200.23\n",
      "Saving new best model\n",
      "59777 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -200.92\n",
      "60940 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -200.77\n",
      "61938 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -201.53\n",
      "62805 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -203.93\n",
      "63302 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -203.24\n",
      "64835 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -200.82\n",
      "65488 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -201.66\n",
      "66662 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -202.65\n",
      "67614 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -202.92\n",
      "68614 timesteps\n",
      "Best mean reward: -200.23 - Last mean reward per episode: -201.66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2e14cd14398c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mresults_plotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_plotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_TIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DDPG LunarLander\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, replay_wrapper)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m                             \u001b[0;31m# Predict next action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m                             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m                             \u001b[0;32massert\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ddpg/ddpg.py\u001b[0m in \u001b[0;36m_policy\u001b[0;34m(self, obs, apply_noise, compute_q)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute_q\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactor_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_with_actor_tf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines.ddpg.policies import LnMlpPolicy\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines import DDPG\n",
    "from stable_baselines.ddpg import AdaptiveParamNoiseSpec\n",
    "from stable_baselines import results_plotter\n",
    "\n",
    "\n",
    "best_mean_reward, n_steps = -np.inf, 0\n",
    "\n",
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
    "    :param _locals: (dict)\n",
    "    :param _globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    # Print stats every 1000 calls\n",
    "    if (n_steps + 1) % 1000 == 0:\n",
    "        # Evaluate policy training performance\n",
    "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "        if len(x) > 0:\n",
    "            mean_reward = np.mean(y[-100:])\n",
    "            print(x[-1], 'timesteps')\n",
    "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
    "\n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                print(\"Saving new best model\")\n",
    "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    n_steps += 1\n",
    "    return True\n",
    "\n",
    "# Create log dir\n",
    "log_dir = \"tmp/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "\n",
    "# Add some param noise for exploration\n",
    "param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.1, desired_action_stddev=0.1)\n",
    "# Because we use parameter noise, we should use a MlpPolicy with layer normalization\n",
    "model = DDPG(LnMlpPolicy, env, param_noise=param_noise, verbose=0)\n",
    "# Train the agent\n",
    "time_steps = 1e5\n",
    "model.learn(total_timesteps=int(time_steps), callback=callback)\n",
    "\n",
    "results_plotter.plot_results([log_dir], time_steps, results_plotter.X_TIMESTEPS, \"DDPG LunarLander\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/common/policies.py:560: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:194: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:210: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/raphael/rl_introduction/venv/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:246: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| approxkl           | 4.4617453e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0125        |\n",
      "| fps                | 385           |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 0.6931087     |\n",
      "| policy_loss        | -0.0010915261 |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 2.86e-06      |\n",
      "| total_timesteps    | 128           |\n",
      "| value_loss         | 46.89326      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.181891e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.000842      |\n",
      "| fps                | 1454           |\n",
      "| n_updates          | 2              |\n",
      "| policy_entropy     | 0.69285005     |\n",
      "| policy_loss        | -0.00061069056 |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 0.333          |\n",
      "| total_timesteps    | 256            |\n",
      "| value_loss         | 39.489075      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.6928072e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.013         |\n",
      "| fps                | 1417          |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.6924062     |\n",
      "| policy_loss        | -0.0001251279 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 0.421         |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 39.15386      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.1433265e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0135        |\n",
      "| fps                | 1671          |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 0.6920715     |\n",
      "| policy_loss        | -0.0012979088 |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 0.512         |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 57.56209      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021524608 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00487       |\n",
      "| fps                | 1712          |\n",
      "| n_updates          | 5             |\n",
      "| policy_entropy     | 0.69025993    |\n",
      "| policy_loss        | -0.004628408  |\n",
      "| serial_timesteps   | 640           |\n",
      "| time_elapsed       | 0.589         |\n",
      "| total_timesteps    | 640           |\n",
      "| value_loss         | 39.449574     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038639604 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0214        |\n",
      "| fps                | 1685          |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 0.68473905    |\n",
      "| policy_loss        | -0.0045230566 |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 0.665         |\n",
      "| total_timesteps    | 768           |\n",
      "| value_loss         | 63.995552     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000106603904 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0138        |\n",
      "| fps                | 1344           |\n",
      "| n_updates          | 7              |\n",
      "| policy_entropy     | 0.6838528      |\n",
      "| policy_loss        | -0.0007072162  |\n",
      "| serial_timesteps   | 896            |\n",
      "| time_elapsed       | 0.742          |\n",
      "| total_timesteps    | 896            |\n",
      "| value_loss         | 54.775963      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.3149276e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0547       |\n",
      "| fps                | 1608          |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 0.6801132     |\n",
      "| policy_loss        | -0.0019206504 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 0.837         |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 44.814144     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001004495  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00987      |\n",
      "| fps                | 1564          |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 0.6765326     |\n",
      "| policy_loss        | -0.0010333952 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 0.918         |\n",
      "| total_timesteps    | 1152          |\n",
      "| value_loss         | 42.88411      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.9893966e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0248       |\n",
      "| fps                | 1680          |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 0.6728375     |\n",
      "| policy_loss        | -0.0014739801 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 1             |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 45.98645      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00085360784 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00591      |\n",
      "| fps                | 1735          |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 0.650102      |\n",
      "| policy_loss        | -0.005775912  |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 1.08          |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 43.258144     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018602566 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0941        |\n",
      "| fps                | 1659          |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 0.6649692     |\n",
      "| policy_loss        | -0.0027031375 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 1.15          |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 58.388638     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 9.078895e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.0463       |\n",
      "| fps                | 1627         |\n",
      "| n_updates          | 13           |\n",
      "| policy_entropy     | 0.66460615   |\n",
      "| policy_loss        | 0.0005943936 |\n",
      "| serial_timesteps   | 1664         |\n",
      "| time_elapsed       | 1.23         |\n",
      "| total_timesteps    | 1664         |\n",
      "| value_loss         | 84.1655      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7805727e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0483       |\n",
      "| fps                | 1717          |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.65217704    |\n",
      "| policy_loss        | -0.0003903705 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 1.31          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 38.30132      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.605282e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0497        |\n",
      "| fps                | 1797          |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 0.6607356     |\n",
      "| policy_loss        | -8.147454e-05 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 1.38          |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 83.53759      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.008772e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0649         |\n",
      "| fps                | 1867           |\n",
      "| n_updates          | 16             |\n",
      "| policy_entropy     | 0.6583119      |\n",
      "| policy_loss        | -0.00052409584 |\n",
      "| serial_timesteps   | 2048           |\n",
      "| time_elapsed       | 1.46           |\n",
      "| total_timesteps    | 2048           |\n",
      "| value_loss         | 64.00194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021406257 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0315        |\n",
      "| fps                | 1839          |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.63624686    |\n",
      "| policy_loss        | 0.0009354808  |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 1.52          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 45.41621      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.0403662e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0344       |\n",
      "| fps                | 1730          |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.64082783    |\n",
      "| policy_loss        | 0.00072466687 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 1.6           |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 37.574017     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 6.629746e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.0239       |\n",
      "| fps                | 1624         |\n",
      "| n_updates          | 19           |\n",
      "| policy_entropy     | 0.6454131    |\n",
      "| policy_loss        | 0.0010896322 |\n",
      "| serial_timesteps   | 2432         |\n",
      "| time_elapsed       | 1.67         |\n",
      "| total_timesteps    | 2432         |\n",
      "| value_loss         | 77.652084    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013568636 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00803       |\n",
      "| fps                | 1755          |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 0.65031064    |\n",
      "| policy_loss        | 0.0002936378  |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 1.75          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 43.356255     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.527572e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.015         |\n",
      "| fps                | 1772          |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.6320389     |\n",
      "| policy_loss        | -0.0009842691 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 1.82          |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 52.34307      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.3247004e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00853       |\n",
      "| fps                | 1841          |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.63701856    |\n",
      "| policy_loss        | -0.0013295203 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 1.9           |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 56.80866      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3645544e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.000834     |\n",
      "| fps                | 1885          |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.6510989     |\n",
      "| policy_loss        | -0.0009999408 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 1.97          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 45.5011       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.14665945e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0301         |\n",
      "| fps                | 1636           |\n",
      "| n_updates          | 24             |\n",
      "| policy_entropy     | 0.644559       |\n",
      "| policy_loss        | 0.0002048926   |\n",
      "| serial_timesteps   | 3072           |\n",
      "| time_elapsed       | 2.03           |\n",
      "| total_timesteps    | 3072           |\n",
      "| value_loss         | 39.394672      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.820792e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0161        |\n",
      "| fps                | 1460          |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.65158117    |\n",
      "| policy_loss        | -0.0015510025 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 2.11          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 71.86757      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.3603087e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0437        |\n",
      "| fps                | 1533          |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.63971347    |\n",
      "| policy_loss        | 5.6965044e-05 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 2.2           |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 44.407166     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.8033142e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0109       |\n",
      "| fps                | 1675          |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 0.6434134     |\n",
      "| policy_loss        | 0.00045884587 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 2.29          |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 38.21286      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.0410895e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.019          |\n",
      "| fps                | 1834           |\n",
      "| n_updates          | 28             |\n",
      "| policy_entropy     | 0.65654963     |\n",
      "| policy_loss        | -0.00029274204 |\n",
      "| serial_timesteps   | 3584           |\n",
      "| time_elapsed       | 2.36           |\n",
      "| total_timesteps    | 3584           |\n",
      "| value_loss         | 63.012554      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2185051e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.042         |\n",
      "| fps                | 1840          |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.615337      |\n",
      "| policy_loss        | 0.000348476   |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 2.43          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 13.875375     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 2.4776857e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.000707       |\n",
      "| fps                | 1901           |\n",
      "| n_updates          | 30             |\n",
      "| policy_entropy     | 0.64342344     |\n",
      "| policy_loss        | -0.00029761507 |\n",
      "| serial_timesteps   | 3840           |\n",
      "| time_elapsed       | 2.5            |\n",
      "| total_timesteps    | 3840           |\n",
      "| value_loss         | 53.202065      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9409048e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00284       |\n",
      "| fps                | 1846          |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 0.64944875    |\n",
      "| policy_loss        | -0.0011556281 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 2.57          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 50.264465     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4410821e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00824       |\n",
      "| fps                | 1795          |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.64787877    |\n",
      "| policy_loss        | 0.00033484178 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 2.64          |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 38.948868     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.6426923e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0306         |\n",
      "| fps                | 1898           |\n",
      "| n_updates          | 33             |\n",
      "| policy_entropy     | 0.65476006     |\n",
      "| policy_loss        | -0.00029693055 |\n",
      "| serial_timesteps   | 4224           |\n",
      "| time_elapsed       | 2.71           |\n",
      "| total_timesteps    | 4224           |\n",
      "| value_loss         | 52.563644      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.32222285e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00179        |\n",
      "| fps                | 1720           |\n",
      "| n_updates          | 34             |\n",
      "| policy_entropy     | 0.64385265     |\n",
      "| policy_loss        | -0.0002566391  |\n",
      "| serial_timesteps   | 4352           |\n",
      "| time_elapsed       | 2.78           |\n",
      "| total_timesteps    | 4352           |\n",
      "| value_loss         | 69.31084       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8334733e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0178       |\n",
      "| fps                | 1552          |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 0.63813955    |\n",
      "| policy_loss        | 0.00011074601 |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 2.86          |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 67.49577      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5847025e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.013          |\n",
      "| fps                | 1545           |\n",
      "| n_updates          | 36             |\n",
      "| policy_entropy     | 0.6536203      |\n",
      "| policy_loss        | -0.00034084404 |\n",
      "| serial_timesteps   | 4608           |\n",
      "| time_elapsed       | 2.94           |\n",
      "| total_timesteps    | 4608           |\n",
      "| value_loss         | 51.09662       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000108498905 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0531         |\n",
      "| fps                | 1702           |\n",
      "| n_updates          | 37             |\n",
      "| policy_entropy     | 0.6418223      |\n",
      "| policy_loss        | -0.00043457095 |\n",
      "| serial_timesteps   | 4736           |\n",
      "| time_elapsed       | 3.02           |\n",
      "| total_timesteps    | 4736           |\n",
      "| value_loss         | 65.330986      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.9188358e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.000229      |\n",
      "| fps                | 1869          |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.6370232     |\n",
      "| policy_loss        | -0.0019440211 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 3.1           |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 54.30033      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.3510387e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0355         |\n",
      "| fps                | 1799           |\n",
      "| n_updates          | 39             |\n",
      "| policy_entropy     | 0.6170907      |\n",
      "| policy_loss        | -0.00025254686 |\n",
      "| serial_timesteps   | 4992           |\n",
      "| time_elapsed       | 3.17           |\n",
      "| total_timesteps    | 4992           |\n",
      "| value_loss         | 25.729374      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.934193e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0179         |\n",
      "| fps                | 1854           |\n",
      "| n_updates          | 40             |\n",
      "| policy_entropy     | 0.62074816     |\n",
      "| policy_loss        | -0.00030425144 |\n",
      "| serial_timesteps   | 5120           |\n",
      "| time_elapsed       | 3.24           |\n",
      "| total_timesteps    | 5120           |\n",
      "| value_loss         | 29.930899      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.7105957e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0375        |\n",
      "| fps                | 1868          |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 0.6234948     |\n",
      "| policy_loss        | -0.0005333272 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 3.31          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 49.609943     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2879955e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0201        |\n",
      "| fps                | 1582          |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 0.6325772     |\n",
      "| policy_loss        | -0.0010431614 |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 3.38          |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 78.99616      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1590258e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00827       |\n",
      "| fps                | 1375          |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 0.6306167     |\n",
      "| policy_loss        | -5.377864e-05 |\n",
      "| serial_timesteps   | 5504          |\n",
      "| time_elapsed       | 3.46          |\n",
      "| total_timesteps    | 5504          |\n",
      "| value_loss         | 73.72659      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.265646e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.036          |\n",
      "| fps                | 1592           |\n",
      "| n_updates          | 44             |\n",
      "| policy_entropy     | 0.6345958      |\n",
      "| policy_loss        | -0.00069761125 |\n",
      "| serial_timesteps   | 5632           |\n",
      "| time_elapsed       | 3.55           |\n",
      "| total_timesteps    | 5632           |\n",
      "| value_loss         | 42.862476      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.7649876e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0187         |\n",
      "| fps                | 1685           |\n",
      "| n_updates          | 45             |\n",
      "| policy_entropy     | 0.6267692      |\n",
      "| policy_loss        | -0.00083944283 |\n",
      "| serial_timesteps   | 5760           |\n",
      "| time_elapsed       | 3.64           |\n",
      "| total_timesteps    | 5760           |\n",
      "| value_loss         | 33.415894      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 6.36033e-06   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00652       |\n",
      "| fps                | 1828          |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 0.6270803     |\n",
      "| policy_loss        | -0.0003473207 |\n",
      "| serial_timesteps   | 5888          |\n",
      "| time_elapsed       | 3.71          |\n",
      "| total_timesteps    | 5888          |\n",
      "| value_loss         | 46.589943     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5299323e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0187        |\n",
      "| fps                | 1886          |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 0.63285774    |\n",
      "| policy_loss        | 1.2791483e-05 |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 3.78          |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 52.50687      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.0041313e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0465         |\n",
      "| fps                | 1823           |\n",
      "| n_updates          | 48             |\n",
      "| policy_entropy     | 0.6310674      |\n",
      "| policy_loss        | -0.00043949514 |\n",
      "| serial_timesteps   | 6144           |\n",
      "| time_elapsed       | 3.85           |\n",
      "| total_timesteps    | 6144           |\n",
      "| value_loss         | 37.10654       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0729432e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00404      |\n",
      "| fps                | 1865          |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.62457734    |\n",
      "| policy_loss        | -0.0008858838 |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 3.92          |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 61.14066      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3056483e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0133        |\n",
      "| fps                | 1802          |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.62514865    |\n",
      "| policy_loss        | -0.002027518  |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 3.99          |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 33.37453      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1095966e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0467        |\n",
      "| fps                | 1762          |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 0.61885506    |\n",
      "| policy_loss        | 0.00022873783 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 4.06          |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 28.865881     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3122457e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0816        |\n",
      "| fps                | 1860          |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 0.5846992     |\n",
      "| policy_loss        | -7.256982e-05 |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 4.14          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 36.50212      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0226229e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0163        |\n",
      "| fps                | 1853          |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.6329983     |\n",
      "| policy_loss        | 5.5750017e-05 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 4.21          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 55.519        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.2805973e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0312         |\n",
      "| fps                | 1882           |\n",
      "| n_updates          | 54             |\n",
      "| policy_entropy     | 0.61039114     |\n",
      "| policy_loss        | -4.9592636e-05 |\n",
      "| serial_timesteps   | 6912           |\n",
      "| time_elapsed       | 4.28           |\n",
      "| total_timesteps    | 6912           |\n",
      "| value_loss         | 40.571877      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.031422e-07   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0579         |\n",
      "| fps                | 1671           |\n",
      "| n_updates          | 55             |\n",
      "| policy_entropy     | 0.6256493      |\n",
      "| policy_loss        | -0.00014096883 |\n",
      "| serial_timesteps   | 7040           |\n",
      "| time_elapsed       | 4.34           |\n",
      "| total_timesteps    | 7040           |\n",
      "| value_loss         | 47.574493      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4412877e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.024         |\n",
      "| fps                | 1394          |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 0.6072989     |\n",
      "| policy_loss        | -0.0011714838 |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 4.42          |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 24.413237     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.109792e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0306       |\n",
      "| fps                | 1702          |\n",
      "| n_updates          | 57            |\n",
      "| policy_entropy     | 0.6185576     |\n",
      "| policy_loss        | -0.0008062322 |\n",
      "| serial_timesteps   | 7296          |\n",
      "| time_elapsed       | 4.51          |\n",
      "| total_timesteps    | 7296          |\n",
      "| value_loss         | 67.43628      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.3134263e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0825        |\n",
      "| fps                | 1577          |\n",
      "| n_updates          | 58            |\n",
      "| policy_entropy     | 0.59512603    |\n",
      "| policy_loss        | -0.0015203787 |\n",
      "| serial_timesteps   | 7424          |\n",
      "| time_elapsed       | 4.59          |\n",
      "| total_timesteps    | 7424          |\n",
      "| value_loss         | 54.86303      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.717171e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0851        |\n",
      "| fps                | 1698          |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.6076887     |\n",
      "| policy_loss        | 0.00015074783 |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 4.67          |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 58.069347     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.29431555e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0013         |\n",
      "| fps                | 1913           |\n",
      "| n_updates          | 60             |\n",
      "| policy_entropy     | 0.6215764      |\n",
      "| policy_loss        | -0.0008801196  |\n",
      "| serial_timesteps   | 7680           |\n",
      "| time_elapsed       | 4.75           |\n",
      "| total_timesteps    | 7680           |\n",
      "| value_loss         | 40.17582       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7397433e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.196         |\n",
      "| fps                | 1741          |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.5979892     |\n",
      "| policy_loss        | -9.7882e-06   |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 4.82          |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 38.837418     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7104015e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.215         |\n",
      "| fps                | 1898          |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 0.62418157    |\n",
      "| policy_loss        | 6.520416e-05  |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 4.89          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 53.25684      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 3.6049725e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0512        |\n",
      "| fps                | 1883          |\n",
      "| n_updates          | 63            |\n",
      "| policy_entropy     | 0.6384476     |\n",
      "| policy_loss        | 0.001665393   |\n",
      "| serial_timesteps   | 8064          |\n",
      "| time_elapsed       | 4.96          |\n",
      "| total_timesteps    | 8064          |\n",
      "| value_loss         | 43.75598      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.903214e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0321       |\n",
      "| fps                | 1819          |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.60039127    |\n",
      "| policy_loss        | -0.0005280938 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 5.03          |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 42.269787     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3859237e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0804       |\n",
      "| fps                | 1590          |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 0.62377954    |\n",
      "| policy_loss        | 0.0009740975  |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 5.1           |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 60.50585      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9030223e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0218       |\n",
      "| fps                | 1581          |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 0.5996603     |\n",
      "| policy_loss        | -3.797107e-05 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 5.18          |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 54.71418      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4832201e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0583        |\n",
      "| fps                | 1476          |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 0.61915016    |\n",
      "| policy_loss        | -0.0006103725 |\n",
      "| serial_timesteps   | 8576          |\n",
      "| time_elapsed       | 5.26          |\n",
      "| total_timesteps    | 8576          |\n",
      "| value_loss         | 38.80109      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5673041e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.203         |\n",
      "| fps                | 1642          |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 0.63500565    |\n",
      "| policy_loss        | 0.0002244336  |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 5.35          |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 53.125206     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0157917e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0131       |\n",
      "| fps                | 1855          |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 0.59985447    |\n",
      "| policy_loss        | 0.00029086636 |\n",
      "| serial_timesteps   | 8832          |\n",
      "| time_elapsed       | 5.43          |\n",
      "| total_timesteps    | 8832          |\n",
      "| value_loss         | 50.01922      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7696504e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0188        |\n",
      "| fps                | 1845          |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 0.6047943     |\n",
      "| policy_loss        | -0.0013104009 |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 5.5           |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 63.34295      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.6856507e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0197         |\n",
      "| fps                | 1697           |\n",
      "| n_updates          | 71             |\n",
      "| policy_entropy     | 0.6105547      |\n",
      "| policy_loss        | -0.00019915611 |\n",
      "| serial_timesteps   | 9088           |\n",
      "| time_elapsed       | 5.57           |\n",
      "| total_timesteps    | 9088           |\n",
      "| value_loss         | 51.007942      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.5760477e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.092         |\n",
      "| fps                | 1874          |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 0.5824751     |\n",
      "| policy_loss        | 0.00057950127 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 5.64          |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 41.42556      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.111044e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0527       |\n",
      "| fps                | 1662          |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.6124886     |\n",
      "| policy_loss        | 0.00010851922 |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 5.71          |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 53.818607     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.4685283e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0934         |\n",
      "| fps                | 1569           |\n",
      "| n_updates          | 74             |\n",
      "| policy_entropy     | 0.61685294     |\n",
      "| policy_loss        | -0.00015399745 |\n",
      "| serial_timesteps   | 9472           |\n",
      "| time_elapsed       | 5.79           |\n",
      "| total_timesteps    | 9472           |\n",
      "| value_loss         | 52.83404       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.296555e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.118         |\n",
      "| fps                | 1487          |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 0.6003457     |\n",
      "| policy_loss        | -0.0017976607 |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 5.87          |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 37.865883     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5518482e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0471       |\n",
      "| fps                | 1819          |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 0.60113585    |\n",
      "| policy_loss        | -0.0015600916 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 5.96          |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 50.745636     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6816833e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.14          |\n",
      "| fps                | 1784          |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 0.5999929     |\n",
      "| policy_loss        | -0.0013435996 |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 6.03          |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 38.746967     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4322938e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.387         |\n",
      "| fps                | 1280          |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 0.60033536    |\n",
      "| policy_loss        | 0.00018369185 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 6.1           |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 52.595135     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/rl_introduction/venv/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "# Optional: PPO2 requires a vectorized environment to run\n",
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done is True:\n",
    "        obs = env.reset()\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
